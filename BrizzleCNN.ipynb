{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/WCLQl3DWa2R6Kq9Z7OEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BryceRodgers7/CoTorch/blob/main/BrizzleCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZnXfkgxhIx2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnF\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# Convert MNIST Image Files into a 4d Tensor (# images, height, width, color)\n",
        "transformTensor = transforms.ToTensor()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get Training Data, turn it into a tensor\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transformTensor)\n",
        "\n",
        "# Test Data, turn it into a tensor\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transformTensor)\n",
        "\n"
      ],
      "metadata": {
        "id": "rE4F8NYoKEXa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)\n",
        "\n",
        "#define our CNN Model\n",
        "# describe (2) convolutional layer(s) and what it's (they're) doing\n",
        "# this is just an example\n",
        "\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "# inputs for conv2 must == outputs for conv1\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "\n",
        "\n",
        "# grab 1 MNIST record\n",
        "for i, (X_Train, y_train) in enumerate(train_data):\n",
        "  break\n",
        "\n",
        "X_Train.shape\n",
        "\n",
        "x = X_Train.view(1,1,28,28)\n",
        "\n",
        "x = nnF.relu(conv1(x)) #relu for activation function\n",
        "\n",
        "# 1 = 1 image??, 6 is the number of layers in the convolutional network, 26x26 is due to not setting a border\n",
        "x.shape\n",
        "\n",
        "# pass thru the pooling layer\n",
        "x = nnF.max_pool2d(x, 1, 2) # kernal=2, stride=2\n",
        "\n",
        "# 1 image, 6 layers of convolutional network, stride of 2 means previous 26 is divided / by 2 = 13\n",
        "x.shape\n",
        "\n",
        "# run convolution 2\n",
        "x = nnF.relu(conv2(x))\n",
        "\n",
        "# 1 image, 16 layers in convo network, no border means -2 so 13 becomes 11\n",
        "x.shape\n",
        "\n",
        "# new pooling layer\n",
        "x = nnF.max_pool2d(x, 2, 2)\n",
        "\n",
        "# has dimensions 1, 16, 5, 5\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKlRFXiSK0BZ",
        "outputId": "5d1d17a2-c275-4312-fee7-4675e42c9ee9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolusion NN model class\n",
        "class ConvolusionalBrizzleNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__():\n",
        "    # convolusion layers\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "    # fully connected layers\n",
        "    self.fc1 = nn.Linear(5*5*16,120)  #\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = nnF.relu(self.conv1(X))\n",
        "    X = nnF.max_pool2d(X, 2, 2) # kernal and stride of 2 as above\n",
        "    # second pass\n",
        "    X = nnF.relu(self.conv2(X)) # kernal and stride of 2 as above\n",
        "    X = nnF.max_pool2d(X,2,2)\n",
        "\n",
        "    # re-view will 'flatten' it out\n",
        "    X = X.view(-1, 16*5*5) # negative one so we can vary the batch size\n",
        "\n",
        "    X = nnF.relu(self.fc1(X))\n",
        "    X = nnF.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return nnF.log_softmax(X, dim=1)\n"
      ],
      "metadata": {
        "id": "g_hLKRF8apzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}